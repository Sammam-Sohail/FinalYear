{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buy price: None\n",
      "Sell prices: []\n",
      "Stop loss: None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Mohib\\Desktop\\FinalYear\\test.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mohib/Desktop/FinalYear/test.ipynb#W0sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Convert the text into numerical features using a count vectorizer\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mohib/Desktop/FinalYear/test.ipynb#W0sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m vectorizer \u001b[39m=\u001b[39m CountVectorizer()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Mohib/Desktop/FinalYear/test.ipynb#W0sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m X \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39;49mfit_transform([text])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mohib/Desktop/FinalYear/test.ipynb#W0sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Initialize and train a linear regression model to predict the sell prices\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mohib/Desktop/FinalYear/test.ipynb#W0sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m model \u001b[39m=\u001b[39m LinearRegression()\n",
      "File \u001b[1;32mc:\\Users\\Mohib\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1338\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1330\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1331\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1332\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1333\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1334\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1335\u001b[0m             )\n\u001b[0;32m   1336\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1338\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[0;32m   1340\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   1341\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Mohib\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1228\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1226\u001b[0m     vocabulary \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1227\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1228\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1229\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1230\u001b[0m         )\n\u001b[0;32m   1232\u001b[0m \u001b[39mif\u001b[39;00m indptr[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m np\u001b[39m.\u001b[39miinfo(np\u001b[39m.\u001b[39mint32)\u001b[39m.\u001b[39mmax:  \u001b[39m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m     \u001b[39mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Preprocess the text\n",
    "text = \"['üî•', 'GRTUSDT', 'FREE', 'SIGNAL', 'üî•', 'Grab', 'GRTUSDT', 'coin', '0.09', '-', '0.11', 'Current', 'Price', '...', '0.099', 'Selling', 'Targets', '0.117', '-', '0.133', '-', '0.16', '-', '0.23', 'Signal', 'type', '...', 'short', 'term', 'GRT', 'coin', 'huge', 'dip', 'time.', 'Price', 'pump', 'time.', '‚ùå', 'Market', 'is‚Ä¶']\"\n",
    "text = ' '.join(text)\n",
    "\n",
    "# Extract the buy price from the text\n",
    "buy_price_pattern = re.compile(r'Buy\\s*:\\s*(\\d*\\.?\\d+)')\n",
    "buy_price_match = buy_price_pattern.search(text)\n",
    "buy_price = float(buy_price_match.group(1)) if buy_price_match else None\n",
    "\n",
    "# Extract the sell prices from the text\n",
    "sell_price_pattern = re.compile(r'Sell\\s*:\\s*(\\d*\\.?\\d+)')\n",
    "sell_prices = [float(match.group(1)) for match in sell_price_pattern.finditer(text)]\n",
    "\n",
    "# Extract the stop loss from the text\n",
    "stop_loss_pattern = re.compile(r'Sl\\s*:\\s*(\\d*\\.?\\d+)')\n",
    "stop_loss_match = stop_loss_pattern.search(text)\n",
    "stop_loss = float(stop_loss_match.group(1)) if stop_loss_match else None\n",
    "\n",
    "# Print the extracted information\n",
    "print(f'Buy price: {buy_price}')\n",
    "print(f'Sell prices: {sell_prices}')\n",
    "print(f'Stop loss: {stop_loss}')\n",
    "\n",
    "# Convert the text into numerical features using a count vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform([text])\n",
    "\n",
    "# Initialize and train a linear regression model to predict the sell prices\n",
    "model = LinearRegression()\n",
    "model.fit(X, sell_prices)\n",
    "\n",
    "# Predict the sell prices for a new text\n",
    "new_text = 'Text containing sell prices'\n",
    "new_X = vectorizer.transform([new_text])\n",
    "predicted_sell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b56cedfc715f32859c7b3e0c7af539013c24260cbdded874583ce504867e8223"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
